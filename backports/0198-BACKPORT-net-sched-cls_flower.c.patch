From: Yevgeny Kliteynik <kliteyn@mellanox.com>
Subject: [PATCH] BACKPORT: net/sched/cls_flower.c

---
 net/sched/cls_flower.c | 385 +++++++++++++++++++++++++++----------------------
 1 file changed, 216 insertions(+), 169 deletions(-)

--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@ -44,6 +44,56 @@
 #define MPLS_LABEL_MASK		(MPLS_LS_LABEL_MASK >> MPLS_LS_LABEL_SHIFT)
 #endif
 
+#ifndef HAVE_TCF_QUEUE_WORK
+static struct workqueue_struct *tc_filter_wq;
+
+static bool tcf_queue_work(struct work_struct *work)
+{
+	return queue_work(tc_filter_wq, work);
+}
+#endif
+
+#ifndef HAVE_TCF_EXTS_GET_DEV
+static int tcf_exts_get_dev(struct net_device *dev, struct tcf_exts *exts,
+			    struct net_device **hw_dev)
+{
+#ifdef CONFIG_NET_CLS_ACT
+	const struct tc_action *a;
+
+	if (tc_no_actions(exts))
+		return -EINVAL;
+
+	tc_for_each_action(a, exts) {
+		if (is_tcf_mirred_egress_redirect(a)) {
+			int ifindex = tcf_mirred_ifindex(a);
+
+			*hw_dev = __dev_get_by_index(dev_net(dev), ifindex);
+			break;
+		}
+	}
+
+	if (*hw_dev)
+		return 0;
+#endif
+	return -EOPNOTSUPP;
+}
+
+static inline bool tc_can_offload(const struct net_device *dev,
+				  const struct tcf_proto *tp)
+{
+	if (!(dev->features & NETIF_F_HW_TC)) {
+		return false;
+	}
+
+	return true;
+}
+#endif
+
+#ifndef HAVE_TCF_EXTS_INIT
+static struct tcf_ext_map flower_ext_map = {
+    .action = TCA_FLOWER_ACT,
+};
+
 #define tcf_exts_init(exts, action, police) (0)
 
 #define tcf_exts_validate(net, tp, tb, est, eptr, ovr) \
@@ -139,6 +189,13 @@ struct cls_fl_filter {
 	u32 mlx5e_flags;
 };
 
+static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f);
+static int fl_hw_replace_filter(struct tcf_proto *tp,
+				struct flow_dissector *dissector,
+				struct fl_flow_key *mask,
+				struct cls_fl_filter *f);
+static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f);
+
 static unsigned short int fl_mask_range(const struct fl_flow_mask *mask)
 {
 	return mask->range.end - mask->range.start;
@@ -274,93 +331,6 @@ static void fl_destroy_filter(struct rcu
 	tcf_queue_work(&f->work);
 }
 
-static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f)
-{
-	struct tc_cls_flower_offload offload = {0};
-	struct net_device *dev = f->hw_dev;
-	struct mlx5e_priv *priv;
-
-	if (!tc_in_hw(f->flags)) {
-		return;
-	}
-
-	offload.command = TC_CLSFLOWER_DESTROY;
-	offload.prio = tp->prio;
-	offload.cookie = (unsigned long)f;
-
-	priv = netdev_priv(dev);
-	mlx5e_delete_flower(priv, &offload, f->mlx5e_flags);
-}
-
-static int fl_hw_replace_filter(struct tcf_proto *tp,
-				struct flow_dissector *dissector,
-				struct fl_flow_key *mask,
-				struct cls_fl_filter *f)
-{
-	struct net_device *dev = tp->q->dev_queue->dev;
-	struct tc_cls_flower_offload offload = {0};
-	struct mlx5e_priv *priv;
-	struct mlx5_eswitch *esw;
-	int err;
-
-	if (!tc_can_offload(dev, tp)) {
-		if (tcf_exts_get_dev(dev, &f->exts, &f->hw_dev) ||
-		    (f->hw_dev && !tc_can_offload(f->hw_dev, tp))) {
-			f->hw_dev = dev;
-			return tc_skip_sw(f->flags) ? -EINVAL : 0;
-		}
-
-		priv = netdev_priv(f->hw_dev);
-		esw = priv->mdev->priv.eswitch;
-		f->hw_dev = mlx5_eswitch_uplink_get_proto_dev(esw, REP_ETH);
-		if (!f->hw_dev) {
-			f->hw_dev = dev;
-			return tc_skip_sw(f->flags) ? -EINVAL : 0;
-		}
-
-		f->mlx5e_flags = MLX5E_TC_EGRESS;
-	} else {
-		f->hw_dev = dev;
-		f->mlx5e_flags = MLX5E_TC_INGRESS;
-	}
-
-	offload.command = TC_CLSFLOWER_REPLACE;
-	offload.prio = tp->prio;
-	offload.cookie = (unsigned long)f;
-	offload.dissector = dissector;
-	offload.mask = mask;
-	offload.key = &f->mkey;
-	offload.exts = &f->exts;
-
-	priv = netdev_priv(f->hw_dev);
-	err = mlx5e_configure_flower(priv, &offload, f->mlx5e_flags);
-	if (!err)
-		f->flags |= TCA_CLS_FLAGS_IN_HW;
-	if (tc_skip_sw(f->flags))
-		return err;
-
-	return 0;
-}
-
-static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
-{
-	struct tc_cls_flower_offload offload = {0};
-	struct net_device *dev = f->hw_dev;
-	struct mlx5e_priv *priv;
-
-	if (!tc_in_hw(f->flags)) {
-		return;
-	}
-
-	offload.command = TC_CLSFLOWER_STATS;
-	offload.prio = tp->prio;
-	offload.cookie = (unsigned long)f;
-	offload.exts = &f->exts;
-
-	priv = netdev_priv(dev);
-	mlx5e_stats_flower(priv, &offload, f->mlx5e_flags);
-}
-
 static void __fl_delete(struct tcf_proto *tp, struct cls_fl_filter *f)
 {
 	struct cls_fl_head *head = rtnl_dereference(tp->root);
@@ -1445,11 +1415,22 @@ static struct tcf_proto_ops cls_fl_ops _
 
 static int __init cls_fl_init(void)
 {
+#ifndef HAVE_TCF_QUEUE_WORK
+	tc_filter_wq = alloc_ordered_workqueue("flower_tc_filter_workqueue", 0);
+	if (!tc_filter_wq)
+		return -ENOMEM;
+#endif
+
 	return register_tcf_proto_ops(&cls_fl_ops);
 }
 
 static void __exit cls_fl_exit(void)
 {
+#ifndef HAVE_TCF_QUEUE_WORK
+	flush_workqueue(tc_filter_wq);
+	destroy_workqueue(tc_filter_wq);
+#endif
+
 	unregister_tcf_proto_ops(&cls_fl_ops);
 }
 
@@ -1491,6 +1472,11 @@ MODULE_LICENSE("GPL v2");
 #include <net/dst.h>
 #include <net/dst_metadata.h>
 
+#include <net/tc_act/tc_mirred.h>
+#include "../../drivers/net/ethernet/mellanox/mlx5/core/en.h"
+#include "../../drivers/net/ethernet/mellanox/mlx5/core/en_tc.h"
+#include "../../drivers/net/ethernet/mellanox/mlx5/core/eswitch.h"
+
 struct fl_flow_key {
 	int	indev_ifindex;
 	struct flow_dissector_key_control control;
@@ -1553,8 +1539,58 @@ struct cls_fl_filter {
 	struct rcu_head	rcu;
 	struct tc_to_netdev tc;
 	struct net_device *hw_dev;
+	u32 mlx5e_flags;
 };
 
+static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f);
+static int fl_hw_replace_filter(struct tcf_proto *tp,
+				struct flow_dissector *dissector,
+				struct fl_flow_key *mask,
+				struct cls_fl_filter *f);
+static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f);
+
+#ifndef HAVE_TCF_EXTS_GET_DEV
+static int tcf_exts_get_dev(struct net_device *dev, struct tcf_exts *exts,
+			    struct net_device **hw_dev)
+{
+#ifdef CONFIG_NET_CLS_ACT
+	const struct tc_action *a;
+	LIST_HEAD(actions);
+
+	if (tc_no_actions(exts))
+		return -EINVAL;
+
+#ifdef HAVE_TCF_EXTS_TO_LIST
+	tcf_exts_to_list(exts, &actions);
+	list_for_each_entry(a, &actions, list) {
+#else
+	tc_for_each_action(a, exts) {
+#endif
+		if (is_tcf_mirred_egress_redirect(a)) {
+			int ifindex = tcf_mirred_ifindex(a);
+
+			*hw_dev = __dev_get_by_index(dev_net(dev), ifindex);
+			break;
+		}
+	}
+
+	if (*hw_dev)
+		return 0;
+#endif
+	return -EOPNOTSUPP;
+}
+
+static inline bool tc_can_offload(const struct net_device *dev,
+                                  const struct tcf_proto *tp)
+{
+	if (!(dev->features & NETIF_F_HW_TC)) {
+		return false;
+	}
+
+	return true;
+}
+#endif
+
 static unsigned short int fl_mask_range(const struct fl_flow_mask *mask)
 {
 	return mask->range.end - mask->range.start;
@@ -1689,88 +1725,6 @@ static void fl_destroy_filter(struct rcu
 	kfree(f);
 }
 
-static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f)
-{
-	struct tc_cls_flower_offload offload = {0};
-	struct net_device *dev = f->hw_dev;
-	struct tc_to_netdev *tc = &f->tc;
-
-	if (!tc_can_offload(dev, tp))
-		return;
-
-	offload.command = TC_CLSFLOWER_DESTROY;
-	offload.prio = tp->prio;
-	offload.cookie = (unsigned long)f;
-
-	tc->type = TC_SETUP_CLSFLOWER;
-	tc->cls_flower = &offload;
-
-	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol, tc);
-}
-
-static int fl_hw_replace_filter(struct tcf_proto *tp,
-				struct flow_dissector *dissector,
-				struct fl_flow_key *mask,
-				struct cls_fl_filter *f)
-{
-	struct net_device *dev = tp->q->dev_queue->dev;
-	struct tc_cls_flower_offload offload = {0};
-	struct tc_to_netdev *tc = &f->tc;
-	int err;
-
-	if (!tc_can_offload(dev, tp)) {
-		if (tcf_exts_get_dev(dev, &f->exts, &f->hw_dev) ||
-		    (f->hw_dev && !tc_can_offload(f->hw_dev, tp))) {
-			f->hw_dev = dev;
-			return tc_skip_sw(f->flags) ? -EINVAL : 0;
-		}
-		dev = f->hw_dev;
-		tc->egress_dev = true;
-	} else {
-		f->hw_dev = dev;
-	}
-
-	offload.command = TC_CLSFLOWER_REPLACE;
-	offload.prio = tp->prio;
-	offload.cookie = (unsigned long)f;
-	offload.dissector = dissector;
-	offload.mask = mask;
-	offload.key = &f->mkey;
-	offload.exts = &f->exts;
-
-	tc->type = TC_SETUP_CLSFLOWER;
-	tc->cls_flower = &offload;
-
-	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
-					    tc);
-	if (!err)
-		f->flags |= TCA_CLS_FLAGS_IN_HW;
-
-	if (tc_skip_sw(f->flags))
-		return err;
-	return 0;
-}
-
-static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
-{
-	struct tc_cls_flower_offload offload = {0};
-	struct net_device *dev = f->hw_dev;
-	struct tc_to_netdev *tc = &f->tc;
-
-	if (!tc_can_offload(dev, tp))
-		return;
-
-	offload.command = TC_CLSFLOWER_STATS;
-	offload.prio = tp->prio;
-	offload.cookie = (unsigned long)f;
-	offload.exts = &f->exts;
-
-	tc->type = TC_SETUP_CLSFLOWER;
-	tc->cls_flower = &offload;
-
-	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol, tc);
-}
-
 static void __fl_delete(struct tcf_proto *tp, struct cls_fl_filter *f)
 {
 	list_del_rcu(&f->list);
@@ -2825,3 +2779,96 @@ MODULE_DESCRIPTION("Flower classifier");
 MODULE_LICENSE("GPL v2");
 
 #endif /* CONFIG_COMPAT_KERNEL_4_9 */
+
+static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f)
+{
+	struct tc_cls_flower_offload offload = {0};
+	struct net_device *dev = f->hw_dev;
+	struct mlx5e_priv *priv;
+
+	if (!tc_in_hw(f->flags)) {
+		return;
+	}
+
+	offload.command = TC_CLSFLOWER_DESTROY;
+#ifndef CONFIG_COMPAT_KERNEL_4_9
+	offload.prio = tp->prio;
+#endif
+	offload.cookie = (unsigned long)f;
+
+	priv = netdev_priv(dev);
+	mlx5e_delete_flower(priv, &offload, f->mlx5e_flags);
+}
+
+static int fl_hw_replace_filter(struct tcf_proto *tp,
+				struct flow_dissector *dissector,
+				struct fl_flow_key *mask,
+				struct cls_fl_filter *f)
+{
+	struct net_device *dev = tp->q->dev_queue->dev;
+	struct tc_cls_flower_offload offload = {0};
+	struct mlx5e_priv *priv;
+	struct mlx5_eswitch *esw;
+	int err;
+
+	if (!tc_can_offload(dev, tp)) {
+		if (tcf_exts_get_dev(dev, &f->exts, &f->hw_dev) ||
+		    (f->hw_dev && !tc_can_offload(f->hw_dev, tp))) {
+			f->hw_dev = dev;
+			return tc_skip_sw(f->flags) ? -EINVAL : 0;
+		}
+
+		priv = netdev_priv(f->hw_dev);
+		esw = priv->mdev->priv.eswitch;
+		f->hw_dev = mlx5_eswitch_uplink_get_proto_dev(esw, REP_ETH);
+		if (!f->hw_dev) {
+			f->hw_dev = dev;
+			return tc_skip_sw(f->flags) ? -EINVAL : 0;
+		}
+
+		f->mlx5e_flags = MLX5E_TC_EGRESS;
+	} else {
+		f->hw_dev = dev;
+		f->mlx5e_flags = MLX5E_TC_INGRESS;
+	}
+
+	offload.command = TC_CLSFLOWER_REPLACE;
+#ifndef CONFIG_COMPAT_KERNEL_4_9
+	offload.prio = tp->prio;
+#endif
+	offload.cookie = (unsigned long)f;
+	offload.dissector = dissector;
+	offload.mask = mask;
+	offload.key = &f->mkey;
+	offload.exts = &f->exts;
+
+	priv = netdev_priv(f->hw_dev);
+	err = mlx5e_configure_flower(priv, &offload, f->mlx5e_flags);
+	if (!err)
+		f->flags |= TCA_CLS_FLAGS_IN_HW;
+	if (tc_skip_sw(f->flags))
+		return err;
+
+	return 0;
+}
+
+static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
+{
+	struct tc_cls_flower_offload offload = {0};
+	struct net_device *dev = f->hw_dev;
+	struct mlx5e_priv *priv;
+
+	if (!tc_in_hw(f->flags)) {
+		return;
+	}
+
+	offload.command = TC_CLSFLOWER_STATS;
+#ifndef CONFIG_COMPAT_KERNEL_4_9
+	offload.prio = tp->prio;
+#endif
+	offload.cookie = (unsigned long)f;
+	offload.exts = &f->exts;
+
+	priv = netdev_priv(dev);
+	mlx5e_stats_flower(priv, &offload, f->mlx5e_flags);
+}
