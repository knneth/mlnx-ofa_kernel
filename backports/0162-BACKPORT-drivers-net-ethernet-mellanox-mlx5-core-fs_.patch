From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/fs_core.c

---
 .../net/ethernet/mellanox/mlx5/core/fs_core.c | 122 ++++++++++++++++--
 1 file changed, 114 insertions(+), 8 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@ -351,7 +351,11 @@ enum fs_i_lock_class {
 };
 
 static const struct rhashtable_params rhash_fte = {
-	.key_len = sizeof_field(struct fs_fte, val),
+#ifndef FIELD_SIZEOF
+        .key_len = sizeof_field(struct fs_fte, val),
+#else
+        .key_len = FIELD_SIZEOF(struct fs_fte, val),
+#endif
 	.key_offset = offsetof(struct fs_fte, val),
 	.head_offset = offsetof(struct fs_fte, hash),
 	.automatic_shrinking = true,
@@ -359,7 +363,11 @@ static const struct rhashtable_params rh
 };
 
 static const struct rhashtable_params rhash_fg = {
-	.key_len = sizeof_field(struct mlx5_flow_group, mask),
+#ifndef FIELD_SIZEOF
+        .key_len = sizeof_field(struct mlx5_flow_group, mask),
+#else
+        .key_len = FIELD_SIZEOF(struct mlx5_flow_group, mask),
+#endif
 	.key_offset = offsetof(struct mlx5_flow_group, mask),
 	.head_offset = offsetof(struct mlx5_flow_group, hash),
 	.automatic_shrinking = true,
@@ -585,7 +593,9 @@ static void del_hw_flow_table(struct fs_
 	fs_get_obj(ft, node);
 	dev = get_dev(&ft->node);
 	root = find_root(&ft->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_ft(ft);
+#endif
 
 	if (node->active) {
 		err = root->cmds->destroy_flow_table(root, ft);
@@ -637,7 +647,9 @@ static void del_sw_hw_dup_rule(struct fs
 
 	fs_get_obj(rule, node);
 	fs_get_obj(fte, rule->node.parent);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_rule(rule);
+#endif
 
 	if (is_fwd_next_action(rule->sw_action)) {
 		mutex_lock(&rule->dest_attr.ft->lock);
@@ -662,7 +674,9 @@ static void del_sw_hw_rule(struct fs_nod
 
 	fs_get_obj(rule, node);
 	fs_get_obj(fte, rule->node.parent);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_rule(rule);
+#endif
 	if (is_fwd_next_action(rule->sw_action)) {
 		mutex_lock(&rule->dest_attr.ft->lock);
 		list_del(&rule->next_ft);
@@ -735,7 +749,9 @@ static void del_hw_fte(struct fs_node *n
 	fs_get_obj(fg, fte->node.parent);
 	fs_get_obj(ft, fg->node.parent);
 
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_fte(fte);
+#endif
 	WARN_ON(fte->act_dests.dests_size);
 	dev = get_dev(&ft->node);
 	root = find_root(&ft->node);
@@ -782,7 +798,11 @@ static void del_sw_fte(struct fs_node *n
 				     &fte->hash,
 				     rhash_fte);
 	WARN_ON(err);
+#ifdef HAVE_IDA_FREE
 	ida_free(&fg->fte_allocator, fte->index - fg->start_index);
+#else
+	ida_simple_remove(&fg->fte_allocator, fte->index - fg->start_index);
+#endif
 	kvfree(fte->dup);
 	kmem_cache_free(steering->ftes_cache, fte);
 }
@@ -797,7 +817,9 @@ static void del_hw_flow_group(struct fs_
 	fs_get_obj(fg, node);
 	fs_get_obj(ft, fg->node.parent);
 	dev = get_dev(&ft->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_del_fg(fg);
+#endif
 
 	root = find_root(&ft->node);
 	if (fg->node.active && root->cmds->destroy_flow_group(root, ft, fg))
@@ -832,8 +854,11 @@ static int insert_fte(struct mlx5_flow_g
 {
 	int index;
 	int ret;
-
+#ifdef HAVE_IDA_ALLOC_MAX
 	index = ida_alloc_max(&fg->fte_allocator, fg->max_ftes - 1, GFP_KERNEL);
+#else
+	index = ida_simple_get(&fg->fte_allocator, 0, fg->max_ftes, GFP_KERNEL);
+#endif
 	if (index < 0)
 		return index;
 
@@ -855,7 +880,11 @@ retry_insert:
 	return 0;
 
 err_ida_remove:
+#ifdef HAVE_IDA_FREE
 	ida_free(&fg->fte_allocator, index);
+#else
+	ida_simple_remove(&fg->fte_allocator, index);
+#endif
 	return ret;
 }
 
@@ -1415,7 +1444,9 @@ static struct mlx5_flow_table *__mlx5_cr
 	fs_prio->num_ft++;
 	up_write_ref_node(&fs_prio->node, false);
 	mutex_unlock(&root->chain_lock);
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_add_ft(ft);
+#endif
 	return ft;
 destroy_ft:
 	root->cmds->destroy_flow_table(root, ft);
@@ -1531,7 +1562,9 @@ struct mlx5_flow_group *mlx5_create_flow
 		tree_put_node(&fg->node, false);
 		return ERR_PTR(err);
 	}
-	trace_mlx5_fs_add_fg(fg);
+#ifndef MLX_DISABLE_TRACEPOINTS
+       trace_mlx5_fs_add_fg(fg);
+#endif
 	fg->node.active = true;
 
 	return fg;
@@ -1838,7 +1871,9 @@ static int create_auto_flow_group(struct
 	err = root->cmds->create_flow_group(root, ft, in, fg);
 	if (!err) {
 		fg->node.active = true;
+#ifndef MLX_DISABLE_TRACEPOINTS
 		trace_mlx5_fs_add_fg(fg);
+#endif
 	}
 
 	kvfree(in);
@@ -2018,13 +2053,17 @@ static struct mlx5_flow_handle *add_rule
 		fte->act_dests.action.action = old_action;
 		return handle;
 	}
+#ifndef MLX_DISABLE_TRACEPOINTS
 	trace_mlx5_fs_set_fte(fte, false);
+#endif
 
 	/* Link newly added rules into the tree. */
 	for (i = 0; i < handle->num_rules; i++) {
 		if (!handle->rule[i]->node.parent) {
 			tree_add_node(&handle->rule[i]->node, &fte->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 			trace_mlx5_fs_add_rule(handle->rule[i]);
+#endif
 		}
 	}
 	return handle;
@@ -2097,9 +2136,9 @@ static int build_match_list(struct match
 	rcu_read_lock();
 	INIT_LIST_HEAD(&match_head->list);
 	/* Collect all fgs which has a matching match_criteria */
-	list = rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
-	/* RCU is atomic, we can't execute FW commands here */
-	rhl_for_each_entry_rcu(g, tmp, list, hash) {
+       list = rhltable_lookup(&ft->fgs_hash, spec, rhash_fg);
+       /* RCU is atomic, we can't execute FW commands here */
+       rhl_for_each_entry_rcu(g, tmp, list, hash) {
 		struct match_list *curr_match;
 
 		if (fg && fg != g)
@@ -2222,7 +2261,9 @@ add_rule_dup_match_fte(struct fs_fte *ft
 
 	for (i = 0; i < handle->num_rules; i++) {
 		tree_add_node(&handle->rule[i]->node, &fte->node);
+#ifndef MLX_DISABLE_TRACEPOINTS
 		trace_mlx5_fs_add_rule(handle->rule[i]);
+#endif
 	}
 
 	return handle;
@@ -3779,6 +3820,7 @@ cleanup:
 	return err;
 }
 
+#if defined(HAVE_DEVLINK_PARAMS_PUBLISHED) || defined(HAVE_DEVLINK_REGISTER_GET_1_PARAMS)
 static int mlx5_fs_mode_validate(struct devlink *devlink, u32 id,
 				 union devlink_param_value val,
 				 struct netlink_ext_ack *extack)
@@ -3814,9 +3856,11 @@ static int mlx5_fs_mode_validate(struct
 
 	eswitch_mode = mlx5_eswitch_mode(dev);
 	if (eswitch_mode == MLX5_ESWITCH_OFFLOADS) {
+#ifdef HAVE_NL_SET_ERR_MSG_FMT_MOD
 		NL_SET_ERR_MSG_FMT_MOD(extack,
 				       "Moving to %s is not supported when eswitch offloads enabled.",
 				       value);
+#endif
 		return -EOPNOTSUPP;
 	}
 
@@ -3824,8 +3868,12 @@ static int mlx5_fs_mode_validate(struct
 }
 
 static int mlx5_fs_mode_set(struct devlink *devlink, u32 id,
+#ifdef HAVE_DEVLINK_PARAM_SET_FUNCTION_POINTER_HAS_EXTACK
 			    struct devlink_param_gset_ctx *ctx,
 			    struct netlink_ext_ack *extack)
+#else
+			    struct devlink_param_gset_ctx *ctx)
+#endif
 {
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	enum mlx5_flow_steering_mode mode;
@@ -3867,6 +3915,7 @@ static const struct devlink_param mlx5_f
 			     mlx5_fs_mode_get, mlx5_fs_mode_set,
 			     mlx5_fs_mode_validate),
 };
+#endif
 
 static int mlx5_devm_fs_mode_validate(struct mlxdevm *mlxdevm, u32 id,
 				      union mlxdevm_param_value val,
@@ -3903,9 +3952,11 @@ static int mlx5_devm_fs_mode_validate(st
 
 	eswitch_mode = mlx5_eswitch_mode(dev);
 	if (eswitch_mode == MLX5_ESWITCH_OFFLOADS) {
+#ifdef HAVE_NL_SET_ERR_MSG_FMT_MOD
 		NL_SET_ERR_MSG_FMT_MOD(extack,
 				       "Moving to %s is not supported when eswitch offloads enabled.",
 				       value);
+#endif
 		return -EOPNOTSUPP;
 	}
 
@@ -3976,10 +4027,21 @@ void mlx5_fs_core_cleanup(struct mlx5_co
 	cleanup_root_ns(steering->egress_root_ns);
 	cleanup_rdma_transport_roots_ns(steering);
 
+/* Similar considerations as detailed in the comment before
+ * devl_params_register in mlx5_fs_core_init
+ */
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	devl_params_unregister(priv_to_devlink(dev), mlx5_fs_params,
 			       ARRAY_SIZE(mlx5_fs_params));
+#endif
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	devm_lock(&mlx5_devm_device_get(dev)->device);
+#endif
 	devm_params_unregister(&mlx5_devm_device_get(dev)->device, mlx5_devm_fs_params,
 			       ARRAY_SIZE(mlx5_devm_fs_params));
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	devm_unlock(&mlx5_devm_device_get(dev)->device);
+#endif
 }
 
 int mlx5_fs_core_init(struct mlx5_core_dev *dev)
@@ -3987,13 +4049,30 @@ int mlx5_fs_core_init(struct mlx5_core_d
 	struct mlx5_flow_steering *steering = dev->priv.steering;
 	int err;
 
+/* Devlink param registration was moved here due to upstream change in
+ * v6.3 introduced by this commit:
+ * db492c1e5b1b net/mlx5: Move flow steering devlink param to flow steering code.
+ * This can be only on kernels >= v6.3 containing devlink changes in
+ * params registration:
+ * 3f716a620e13 devlink: put couple of WARN_ONs in devlink_param_driverinit_value_get()
+ * 075935f0ae0f devlink: protect devlink param list by instance lock
+ * The later also introduced devl_params_register as API - use it as
+ * a HAVE flag
+ */
+#ifdef HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET
 	err = devl_params_register(priv_to_devlink(dev), mlx5_fs_params,
 				   ARRAY_SIZE(mlx5_fs_params));
 	if (err)
 		return err;
-
+#endif
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	devm_lock(&mlx5_devm_device_get(dev)->device);
+#endif
 	err = devm_params_register(&mlx5_devm_device_get(dev)->device, mlx5_devm_fs_params,
 				   ARRAY_SIZE(mlx5_devm_fs_params));
+#ifndef HAVE_DEVL_TRAP_GROUPS_REGISTER
+	devm_unlock(&mlx5_devm_device_get(dev)->device);
+#endif
 	if (err)
 		goto err;
 
@@ -4076,6 +4155,14 @@ void mlx5_fs_core_free(struct mlx5_core_
 {
 	struct mlx5_flow_steering *steering = dev->priv.steering;
 
+/* Similar considerations as detailed in the comment before
+ * devlink_params_register in mlx5_fs_core_alloc
+ */
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) && !defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
+	devlink_params_unregister(priv_to_devlink(dev), mlx5_fs_params,
+				  ARRAY_SIZE(mlx5_fs_params));
+#endif
+
 	kmem_cache_destroy(steering->ftes_cache);
 	kmem_cache_destroy(steering->fgs_cache);
 	kfree(steering);
@@ -4125,6 +4212,25 @@ int mlx5_fs_core_alloc(struct mlx5_core_
 		goto err;
 	}
 
+/* Devlink param register was moved to mlx5_fs_core_init to comply
+ * with upstream changes introduced in v6.3 by:
+ * 3f716a620e13 devlink: put couple of WARN_ONs in devlink_param_driverinit_value_get()
+ * 075935f0ae0f devlink: protect devlink param list by instance lock
+ * The later also introduced devl_params_unregister as API.
+ * In order to support devlink params over older kernel version (<
+ * v6.3) registering the devlink params should move to an earlier stage
+ * as it was before (mlx5_init_one).
+ * Use HAVE_DEVLINK_PARAM_REGISTER to detrmine devlink params ARE
+ * supported and !HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET to detrmine
+ * kernel < v6.3
+ */
+#if defined(HAVE_DEVLINK_PARAM_REGISTER) && !defined(HAVE_DEVL_PARAM_DRIVERINIT_VALUE_GET)
+	err = devlink_params_register(priv_to_devlink(dev), mlx5_fs_params,
+				      ARRAY_SIZE(mlx5_fs_params));
+	if (err)
+		return err;
+#endif
+
 	return 0;
 
 err:
