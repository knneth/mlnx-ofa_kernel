From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c

Change-Id: Ib35c58c87c2485ca97d901d2fb05d51d3fa23ea1
---
 .../net/ethernet/mellanox/mlx5/core/lag/lag.c | 101 +++++++++++++++++-
 1 file changed, 99 insertions(+), 2 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/lag/lag.c
@@ -31,7 +31,6 @@
  */
 
 #include <linux/netdevice.h>
-#include <net/bonding.h>
 #include <linux/mlx5/driver.h>
 #include <linux/mlx5/eswitch.h>
 #include <linux/mlx5/vport.h>
@@ -40,8 +39,11 @@
 #include "mlx5_core.h"
 #include "eswitch.h"
 #include "esw/acl/ofld.h"
+
+#include <net/bonding.h>
+
+
 #include "lag.h"
-#include "mp.h"
 #include "mpesw.h"
 
 
@@ -51,6 +53,7 @@
  */
 static DEFINE_SPINLOCK(lag_lock);
 
+
 static int get_port_sel_mode(enum mlx5_lag_mode mode, unsigned long flags)
 {
 	if (test_bit(MLX5_LAG_MODE_FLAG_HASH_BASED, &flags))
@@ -175,6 +178,9 @@ static void mlx5_infer_tx_disabled(struc
 				   u8 *ports, int *num_disabled)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	*num_disabled = 0;
 	mlx5_ldev_for_each(i, 0, ldev)
@@ -187,6 +193,9 @@ void mlx5_infer_tx_enabled(struct lag_tr
 			   u8 *ports, int *num_enabled)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	*num_enabled = 0;
 	mlx5_ldev_for_each(i, 0, ldev)
@@ -224,6 +233,9 @@ static void mlx5_lag_print_mapping(struc
 		buf[written - 2] = 0;
 		mlx5_core_info(dev, "lag map active ports: %s\n", buf);
 	} else {
+		#ifndef HAVE_STD_GNU_99
+			int tmp;
+		#endif
 		mlx5_ldev_for_each(i, 0, ldev) {
 			for (j  = 0; j < ldev->buckets; j++) {
 				idx = i * ldev->buckets + j;
@@ -249,7 +261,11 @@ static void mlx5_ldev_free(struct kref *
 
 	if (ldev->nb.notifier_call) {
 		net = read_pnet(&ldev->net);
+#ifdef HAVE_UNREGISTER_NETDEVICE_NOTIFIER_NET
 		unregister_netdevice_notifier_net(net, &ldev->nb);
+#else
+		unregister_netdevice_notifier(&ldev->nb);
+#endif
 	}
 
 	mlx5_lag_mp_cleanup(ldev);
@@ -290,7 +306,11 @@ static struct mlx5_lag *mlx5_lag_dev_all
 
 	ldev->nb.notifier_call = mlx5_lag_netdev_event;
 	write_pnet(&ldev->net, mlx5_core_net(dev));
+#ifdef HAVE_UNREGISTER_NETDEVICE_NOTIFIER_NET
 	if (register_netdevice_notifier_net(read_pnet(&ldev->net), &ldev->nb)) {
+#else
+	if (register_netdevice_notifier(&ldev->nb)) {
+#endif
 		ldev->nb.notifier_call = NULL;
 		mlx5_core_err(dev, "Failed to register LAG netdev notifier\n");
 	}
@@ -311,6 +331,9 @@ int mlx5_lag_dev_get_netdev_idx(struct m
 				struct net_device *ndev)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev)
 		if (ldev->pf[i].netdev == ndev)
@@ -322,6 +345,9 @@ int mlx5_lag_dev_get_netdev_idx(struct m
 int mlx5_lag_get_dev_index_by_seq(struct mlx5_lag *ldev, int seq)
 {
 	int i, num = 0;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (!ldev)
 		return -ENOENT;
@@ -337,6 +363,9 @@ int mlx5_lag_get_dev_index_by_seq(struct
 int mlx5_lag_num_devs(struct mlx5_lag *ldev)
 {
 	int i, num = 0;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (!ldev)
 		return 0;
@@ -351,6 +380,9 @@ int mlx5_lag_num_devs(struct mlx5_lag *l
 int mlx5_lag_num_netdevs(struct mlx5_lag *ldev)
 {
 	int i, num = 0;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (!ldev)
 		return 0;
@@ -390,6 +422,9 @@ static void mlx5_infer_tx_affinity_mappi
 	u32 rand;
 	int i;
 	int j;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev) {
 		if (tracker->netdev_state[i].tx_enabled &&
@@ -426,6 +461,9 @@ static void mlx5_infer_tx_affinity_mappi
 static bool mlx5_lag_has_drop_rule(struct mlx5_lag *ldev)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev)
 		if (ldev->pf[i].has_drop)
@@ -436,6 +474,9 @@ static bool mlx5_lag_has_drop_rule(struc
 static void mlx5_lag_drop_rule_cleanup(struct mlx5_lag *ldev)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev) {
 		if (!ldev->pf[i].has_drop)
@@ -525,6 +566,9 @@ static struct net_device *mlx5_lag_activ
 	struct mlx5_lag *ldev;
 	unsigned long flags;
 	int i, last_idx;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	spin_lock_irqsave(&lag_lock, flags);
 	ldev = mlx5_lag_dev(dev);
@@ -560,6 +604,9 @@ void mlx5_modify_lag(struct mlx5_lag *ld
 	int err;
 	int i;
 	int j;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (first_idx < 0)
 		return;
@@ -719,6 +766,9 @@ static int mlx5_lag_create_single_fdb(st
 	struct mlx5_core_dev *dev0;
 	int i, j;
 	int err;
+#ifndef HAVE_STD_GNU_99
+	int tmp, tmp1;
+#endif
 
 	if (first_idx < 0)
 		return -EINVAL;
@@ -854,6 +904,9 @@ int mlx5_deactivate_lag(struct mlx5_lag
 	struct mlx5_core_dev *dev0;
 	int err;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (first_idx < 0)
 		return -EINVAL;
@@ -904,6 +957,9 @@ bool mlx5_lag_check_prereq(struct mlx5_l
 #endif
 	bool roce_support;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (first_idx < 0 || mlx5_lag_num_devs(ldev) != ldev->ports)
 		return false;
@@ -937,6 +993,9 @@ bool mlx5_lag_check_prereq(struct mlx5_l
 void mlx5_lag_add_devices(struct mlx5_lag *ldev)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev) {
 		if (ldev->pf[i].dev->priv.flags &
@@ -951,6 +1010,9 @@ void mlx5_lag_add_devices(struct mlx5_la
 void mlx5_lag_remove_devices(struct mlx5_lag *ldev)
 {
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev) {
 		if (ldev->pf[i].dev->priv.flags &
@@ -970,6 +1032,9 @@ void mlx5_disable_lag(struct mlx5_lag *l
 	bool roce_lag;
 	int err;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (idx < 0)
 		return;
@@ -1006,6 +1071,9 @@ bool mlx5_lag_shared_fdb_supported(struc
 	int idx = mlx5_lag_get_dev_index_by_seq(ldev, MLX5_LAG_P1);
 	struct mlx5_core_dev *dev;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (idx < 0)
 		return false;
@@ -1037,6 +1105,9 @@ static bool mlx5_lag_is_roce_lag(struct
 {
 	bool roce_lag = true;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	mlx5_ldev_for_each(i, 0, ldev)
 		roce_lag = roce_lag && !mlx5_sriov_is_enabled(ldev->pf[i].dev);
@@ -1070,6 +1141,9 @@ static void mlx5_do_bond(struct mlx5_lag
 	bool do_bond, roce_lag;
 	int err;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (idx < 0)
 		return;
@@ -1121,6 +1195,7 @@ static void mlx5_do_bond(struct mlx5_lag
 			dev0->priv.flags &= ~MLX5_PRIV_FLAGS_DISABLE_IB_ADEV;
 			mlx5_rescan_drivers_locked(dev0);
 
+#ifdef CONFIG_MLX5_ESWITCH
 			mlx5_ldev_for_each(i, 0, ldev) {
 				err = mlx5_eswitch_reload_ib_reps(ldev->pf[i].dev->priv.eswitch);
 				if (err)
@@ -1137,6 +1212,7 @@ static void mlx5_do_bond(struct mlx5_lag
 				mlx5_core_err(dev0, "Failed to enable lag\n");
 				return;
 			}
+#endif
 		}
 		if (tracker.tx_type == NETDEV_LAG_TX_TYPE_ACTIVEBACKUP) {
 			ndev = mlx5_lag_active_backup_get_netdev(dev0);
@@ -1221,6 +1297,9 @@ static int mlx5_handle_changeupper_event
 	int num_slaves = 0;
 	int changed = 0;
 	int i, idx = -1;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	if (!netif_is_lag_master(upper))
 		return 0;
@@ -1233,8 +1312,12 @@ static int mlx5_handle_changeupper_event
 	 * as slaves (e.g., if a new slave is added to a master that bonds two
 	 * of our netdevs, we should unbond).
 	 */
+#ifdef for_each_netdev_in_bond_rcu
 	rcu_read_lock();
 	for_each_netdev_in_bond_rcu(upper, ndev_tmp) {
+#else
+	for_each_netdev_in_bond(upper, ndev_tmp) {
+#endif
 		mlx5_ldev_for_each(i, 0, ldev) {
 			if (ldev->pf[i].netdev == ndev_tmp) {
 				idx++;
@@ -1250,7 +1333,9 @@ static int mlx5_handle_changeupper_event
 
 		num_slaves++;
 	}
+#ifdef for_each_netdev_in_bond_rcu
 	rcu_read_unlock();
+#endif
 
 	/* None of this lagdev's netdevs are slaves of this master. */
 	if (!(bond_status & GENMASK(ldev->ports - 1, 0)))
@@ -1424,6 +1509,9 @@ static void mlx5_ldev_remove_netdev(stru
 {
 	unsigned long flags;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	spin_lock_irqsave(&lag_lock, flags);
 	mlx5_ldev_for_each(i, 0, ldev) {
@@ -1762,6 +1850,9 @@ u8 mlx5_lag_get_slave_port(struct mlx5_c
 	unsigned long flags;
 	u8 port = 0;
 	int i;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	spin_lock_irqsave(&lag_lock, flags);
 	ldev = mlx5_lag_dev(dev);
@@ -1801,6 +1892,9 @@ struct mlx5_core_dev *mlx5_lag_get_next_
 	struct mlx5_lag *ldev;
 	unsigned long flags;
 	int idx;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	spin_lock_irqsave(&lag_lock, flags);
 	ldev = mlx5_lag_dev(dev);
@@ -1839,6 +1933,9 @@ int mlx5_lag_query_cong_counters(struct
 	unsigned long flags;
 	int num_ports;
 	void *out;
+#ifndef HAVE_STD_GNU_99
+	int tmp;
+#endif
 
 	out = kvzalloc(outlen, GFP_KERNEL);
 	if (!out)
