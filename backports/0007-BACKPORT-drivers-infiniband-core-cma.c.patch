From: Valentine Fatiev <valentinef@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/core/cma.c

---
 drivers/infiniband/core/cma.c | 70 +++++++++++++++++++++++++++++++++++
 1 file changed, 70 insertions(+)

--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@ -43,6 +43,9 @@
 MODULE_AUTHOR("Sean Hefty");
 MODULE_DESCRIPTION("Generic RDMA CM Agent");
 MODULE_LICENSE("Dual BSD/GPL");
+#ifdef RETPOLINE_MLNX
+MODULE_INFO(retpoline, "Y");
+#endif
 
 #define CMA_CM_RESPONSE_TIMEOUT 22
 #define CMA_MAX_CM_RETRIES 15
@@ -595,7 +598,9 @@ static void _cma_attach_to_dev(struct rd
 		rdma_node_get_transport(cma_dev->device->node_type);
 	list_add_tail(&id_priv->device_item, &cma_dev->id_list);
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_id_attach(id_priv, cma_dev->device);
+#endif
 }
 
 static void cma_attach_to_dev(struct rdma_id_private *id_priv,
@@ -1160,12 +1165,16 @@ int rdma_create_qp(struct rdma_cm_id *id
 	id->qp = qp;
 	id_priv->qp_num = qp->qp_num;
 	id_priv->srq = (qp->srq != NULL);
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_qp_create(id_priv, pd, qp_init_attr, 0);
+#endif
 	return 0;
 out_destroy:
 	ib_destroy_qp(qp);
 out_err:
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_qp_create(id_priv, pd, qp_init_attr, ret);
+#endif
 	return ret;
 }
 EXPORT_SYMBOL(rdma_create_qp);
@@ -1175,7 +1184,9 @@ void rdma_destroy_qp(struct rdma_cm_id *
 	struct rdma_id_private *id_priv;
 
 	id_priv = container_of(id, struct rdma_id_private, id);
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_qp_destroy(id_priv);
+#endif
 	mutex_lock(&id_priv->qp_mutex);
 	ib_destroy_qp(id_priv->id.qp);
 	id_priv->id.qp = NULL;
@@ -2107,7 +2118,9 @@ static void destroy_id_handler_unlock(st
 	enum rdma_cm_state state;
 	unsigned long flags;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_id_destroy(id_priv);
+#endif
 
 	/*
 	 * Setting the state to destroyed under the handler mutex provides a
@@ -2146,7 +2159,9 @@ static int cma_rep_recv(struct rdma_id_p
 	if (ret)
 		goto reject;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_send_rtu(id_priv);
+#endif
 	ret = ib_send_cm_rtu(id_priv->cm_id.ib, NULL, 0);
 	if (ret)
 		goto reject;
@@ -2155,7 +2170,9 @@ static int cma_rep_recv(struct rdma_id_p
 reject:
 	pr_debug_ratelimited("RDMA CM: CONNECT_ERROR: failed to handle reply. status %d\n", ret);
 	cma_modify_qp_err(id_priv);
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_send_rej(id_priv);
+#endif
 	ib_send_cm_rej(id_priv->cm_id.ib, IB_CM_REJ_CONSUMER_DEFINED,
 		       NULL, 0, NULL, 0);
 	return ret;
@@ -2185,9 +2202,13 @@ static int cma_cm_event_handler(struct r
 
 	lockdep_assert_held(&id_priv->handler_mutex);
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_event_handler(id_priv, event);
+#endif
 	ret = id_priv->id.event_handler(&id_priv->id, event);
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_event_done(id_priv, event, ret);
+#endif
 	return ret;
 }
 
@@ -2216,7 +2237,9 @@ static int cma_ib_handler(struct ib_cm_i
 	case IB_CM_REP_RECEIVED:
 		if (state == RDMA_CM_CONNECT &&
 		    (id_priv->id.qp_type != IB_QPT_UD)) {
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 			trace_cm_send_mra(id_priv);
+#endif
 			ib_send_cm_mra(cm_id, CMA_CM_MRA_SETTING, NULL, 0);
 		}
 		if (id_priv->id.qp) {
@@ -2427,7 +2450,9 @@ static int cma_ib_req_handler(struct ib_
 	if (IS_ERR(listen_id))
 		return PTR_ERR(listen_id);
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_req_handler(listen_id, ib_event->event);
+#endif
 	if (!cma_ib_check_req_qp_type(&listen_id->id, ib_event)) {
 		ret = -EINVAL;
 		goto net_dev_put;
@@ -2478,7 +2503,9 @@ static int cma_ib_req_handler(struct ib_
 
 	if (READ_ONCE(conn_id->state) == RDMA_CM_CONNECT &&
 	    conn_id->id.qp_type != IB_QPT_UD) {
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 		trace_cm_send_mra(cm_id->context);
+#endif
 		ib_send_cm_mra(cm_id, CMA_CM_MRA_SETTING, NULL, 0);
 	}
 	mutex_unlock(&conn_id->handler_mutex);
@@ -2721,7 +2748,9 @@ static int cma_listen_handler(struct rdm
 
 	id->context = id_priv->id.context;
 	id->event_handler = id_priv->id.event_handler;
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_event_handler(id_priv, event);
+#endif
 	return id_priv->id.event_handler(id, event);
 }
 
@@ -3240,9 +3269,17 @@ struct iboe_prio_tc_map {
 };
 
 static int get_lower_vlan_dev_tc(struct net_device *dev,
+#ifdef HAVE_NETDEV_NESTED_PRIV_STRUCT
 				 struct netdev_nested_priv *priv)
+#else
+				 void *data)
+#endif
 {
+#ifdef HAVE_NETDEV_NESTED_PRIV_STRUCT
 	struct iboe_prio_tc_map *map = (struct iboe_prio_tc_map *)priv->data;
+#else
+	struct iboe_prio_tc_map *map = data;
+#endif
 
 	if (is_vlan_dev(dev))
 		map->output_tc = get_vlan_ndev_tc(dev, map->input_prio);
@@ -3261,18 +3298,26 @@ static int iboe_tos_to_sl(struct net_dev
 {
 	struct iboe_prio_tc_map prio_tc_map = {};
 	int prio = rt_tos2priority(tos);
+#ifdef HAVE_NETDEV_NESTED_PRIV_STRUCT
 	struct netdev_nested_priv priv;
+#endif
 
 	/* If VLAN device, get it directly from the VLAN netdev */
 	if (is_vlan_dev(ndev))
 		return get_vlan_ndev_tc(ndev, prio);
 
 	prio_tc_map.input_prio = prio;
+#ifdef HAVE_NETDEV_NESTED_PRIV_STRUCT
 	priv.data = (void *)&prio_tc_map;
+#endif
 	rcu_read_lock();
 	netdev_walk_all_lower_dev_rcu(ndev,
 				      get_lower_vlan_dev_tc,
+#ifdef HAVE_NETDEV_NESTED_PRIV_STRUCT
 				      &priv);
+#else
+				      &prio_tc_map);
+#endif
 	rcu_read_unlock();
 	/* If map is found from lower device, use it; Otherwise
 	 * continue with the current netdevice to get priority to tc map.
@@ -3759,7 +3804,11 @@ static int cma_alloc_any_port(enum rdma_
 
 	inet_get_local_port_range(net, &low, &high);
 	remaining = (high - low) + 1;
+#ifdef HAVE_GET_RANDOM_U32_INCLUSIVE
 	rover = get_random_u32_inclusive(low, remaining + low - 1);
+#else
+	rover = prandom_u32_max(remaining) + low;
+#endif
 retry:
 	if (last_used_port != rover) {
 		struct rdma_bind_list *bind_list;
@@ -4335,7 +4384,9 @@ static int cma_resolve_ib_udp(struct rdm
 	req.timeout_ms = 1 << (CMA_CM_RESPONSE_TIMEOUT - 8);
 	req.max_cm_retries = CMA_MAX_CM_RETRIES;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_send_sidr_req(id_priv);
+#endif
 	ret = ib_send_cm_sidr_req(id_priv->cm_id.ib, &req);
 	if (ret) {
 		ib_destroy_cm_id(id_priv->cm_id.ib);
@@ -4412,7 +4463,9 @@ static int cma_connect_ib(struct rdma_id
 	req.ece.vendor_id = id_priv->ece.vendor_id;
 	req.ece.attr_mod = id_priv->ece.attr_mod;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_send_req(id_priv);
+#endif
 	ret = ib_send_cm_req(id_priv->cm_id.ib, &req);
 out:
 	if (ret && !IS_ERR(id)) {
@@ -4586,7 +4639,9 @@ static int cma_accept_ib(struct rdma_id_
 	rep.ece.vendor_id = id_priv->ece.vendor_id;
 	rep.ece.attr_mod = id_priv->ece.attr_mod;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_send_rep(id_priv);
+#endif
 	ret = ib_send_cm_rep(id_priv->cm_id.ib, &rep);
 out:
 	return ret;
@@ -4643,7 +4698,9 @@ static int cma_send_sidr_rep(struct rdma
 	rep.private_data = private_data;
 	rep.private_data_len = private_data_len;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_send_sidr_rep(id_priv);
+#endif
 	return ib_send_cm_sidr_rep(id_priv->cm_id.ib, &rep);
 }
 
@@ -4780,7 +4837,9 @@ int rdma_reject(struct rdma_cm_id *id, c
 			ret = cma_send_sidr_rep(id_priv, IB_SIDR_REJECT, 0,
 						private_data, private_data_len);
 		} else {
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 			trace_cm_send_rej(id_priv);
+#endif
 			ret = ib_send_cm_rej(id_priv->cm_id.ib, reason, NULL, 0,
 					     private_data, private_data_len);
 		}
@@ -4809,6 +4868,7 @@ int rdma_disconnect(struct rdma_cm_id *i
 		if (ret)
 			goto out;
 		/* Initiate or respond to a disconnect. */
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 		trace_cm_disconnect(id_priv);
 		if (ib_send_cm_dreq(id_priv->cm_id.ib, NULL, 0)) {
 			if (!ib_send_cm_drep(id_priv->cm_id.ib, NULL, 0))
@@ -4816,6 +4876,10 @@ int rdma_disconnect(struct rdma_cm_id *i
 		} else {
 			trace_cm_sent_dreq(id_priv);
 		}
+#else
+		if (ib_send_cm_dreq(id_priv->cm_id.ib, NULL, 0))
+			ib_send_cm_drep(id_priv->cm_id.ib, NULL, 0);
+#endif
 	} else if (rdma_cap_iw_cm(id->device, id->port_num)) {
 		ret = iw_cm_disconnect(id_priv->cm_id.iw, 0);
 	} else
@@ -5289,7 +5353,9 @@ static void cma_send_device_removal_put(
 		 */
 		cma_id_put(id_priv);
 		mutex_unlock(&id_priv->handler_mutex);
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 		trace_cm_id_destroy(id_priv);
+#endif
 		_destroy_id(id_priv, state);
 		return;
 	}
@@ -5395,7 +5461,9 @@ static int cma_add_one(struct ib_device
 	}
 	mutex_unlock(&lock);
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_add_one(device);
+#endif
 	return 0;
 
 free_listen:
@@ -5417,7 +5485,9 @@ static void cma_remove_one(struct ib_dev
 {
 	struct cma_device *cma_dev = client_data;
 
+#if !defined(MLX_DISABLE_TRACEPOINTS)
 	trace_cm_remove_one(device);
+#endif
 
 	mutex_lock(&lock);
 	list_del(&cma_dev->list);
