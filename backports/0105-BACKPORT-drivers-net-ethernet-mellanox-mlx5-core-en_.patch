From: Mikhael Goikhman <migo@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en_stats.h

Change-Id: I185ffbb2a9ecce3dd28c151e271ac595a22f7acb
---
 .../ethernet/mellanox/mlx5/core/en_stats.h    | 53 +++++++++++++------
 1 file changed, 37 insertions(+), 16 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
@@ -136,15 +136,19 @@ struct mlx5e_sw_stats {
 	u64 rx_csum_complete_tail;
 	u64 rx_csum_complete_tail_slow;
 	u64 rx_csum_unnecessary_inner;
-	u64 rx_xdp_drop;
-	u64 rx_xdp_redirect;
-	u64 rx_xdp_tx_xmit;
-	u64 rx_xdp_tx_mpwqe;
-	u64 rx_xdp_tx_inlnw;
-	u64 rx_xdp_tx_nops;
-	u64 rx_xdp_tx_full;
-	u64 rx_xdp_tx_err;
-	u64 rx_xdp_tx_cqe;
+#ifdef HAVE_XDP_BUFF
+       u64 rx_xdp_drop;
+#ifdef HAVE_XDP_REDIRECT
+       u64 rx_xdp_redirect;
+#endif
+       u64 rx_xdp_tx_xmit;
+       u64 rx_xdp_tx_nops;
+       u64 rx_xdp_tx_mpwqe;
+       u64 rx_xdp_tx_inlnw;
+       u64 rx_xdp_tx_full;
+       u64 rx_xdp_tx_err;
+       u64 rx_xdp_tx_cqe;
+#endif
 	u64 tx_csum_none;
 	u64 tx_csum_partial;
 	u64 tx_csum_partial_inner;
@@ -155,13 +159,20 @@ struct mlx5e_sw_stats {
 	u64 tx_cqes;
 	u64 tx_queue_wake;
 	u64 tx_cqe_err;
-	u64 tx_xdp_xmit;
-	u64 tx_xdp_mpwqe;
-	u64 tx_xdp_inlnw;
-	u64 tx_xdp_nops;
-	u64 tx_xdp_full;
-	u64 tx_xdp_err;
-	u64 tx_xdp_cqes;
+#ifdef CONFIG_COMPAT_LRO_ENABLED_IPOIB
+	u64 rx_sw_lro_aggregated;
+	u64 rx_sw_lro_flushed;
+	u64 rx_sw_lro_no_desc;
+#endif
+#ifdef HAVE_XDP_REDIRECT
+       u64 tx_xdp_xmit;
+       u64 tx_xdp_mpwqe;
+       u64 tx_xdp_inlnw;
+       u64 tx_xdp_nops;
+       u64 tx_xdp_full;
+       u64 tx_xdp_err;
+       u64 tx_xdp_cqes;
+#endif
 	u64 tx_cqe_compress_blks;
 	u64 tx_cqe_compress_pkts;
 	u64 rx_wqe_err;
@@ -190,6 +201,7 @@ struct mlx5e_sw_stats {
 	u64 ch_eq_rearm;
 
 #ifdef CONFIG_MLX5_EN_TLS
+#ifdef HAVE_UAPI_LINUX_TLS_H
 	u64 tx_tls_encrypted_packets;
 	u64 tx_tls_encrypted_bytes;
 	u64 tx_tls_ctx;
@@ -212,6 +224,7 @@ struct mlx5e_sw_stats {
 	u64 rx_tls_resync_res_ok;
 	u64 rx_tls_resync_res_skip;
 	u64 rx_tls_err;
+#endif /* HAVE_UAPI_LINUX_TLS_H */
 #endif
 
 	u64 rx_xsk_packets;
@@ -316,8 +329,12 @@ struct mlx5e_rq_stats {
 	u64 mcast_bytes;
 	u64 ecn_mark;
 	u64 removed_vlan_packets;
+#ifdef HAVE_XDP_BUFF
 	u64 xdp_drop;
+#ifdef HAVE_XDP_REDIRECT
 	u64 xdp_redirect;
+#endif
+#endif
 	u64 wqe_err;
 	u64 mpwqe_filler_cqes;
 	u64 mpwqe_filler_strides;
@@ -337,6 +354,7 @@ struct mlx5e_rq_stats {
 	u64 arfs_err;
 	u64 recover;
 #ifdef CONFIG_MLX5_EN_TLS
+#ifdef HAVE_UAPI_LINUX_TLS_H
 	u64 tls_decrypted_packets;
 	u64 tls_decrypted_bytes;
 	u64 tls_ctx;
@@ -348,6 +366,7 @@ struct mlx5e_rq_stats {
 	u64 tls_resync_res_ok;
 	u64 tls_resync_res_skip;
 	u64 tls_err;
+#endif /* HAVE_UAPI_LINUX_TLS_H */
 #endif
 };
 
@@ -391,6 +410,7 @@ struct mlx5e_sq_stats {
 	u64 cqe_err;
 };
 
+#ifdef HAVE_XDP_BUFF
 struct mlx5e_xdpsq_stats {
 	u64 xmit;
 	u64 mpwqe;
@@ -401,6 +421,7 @@ struct mlx5e_xdpsq_stats {
 	/* dirtied @completion */
 	u64 cqes ____cacheline_aligned_in_smp;
 };
+#endif
 
 struct mlx5e_ch_stats {
 	u64 events;
